# comp7607_group_project

# Reading list 
> Please 1) Make sure dataset is public dataset and accessible 2) Remark if code is available
## Frankie
- ACL 2021 Prefix-Tuning: Optimizing Continuous Prompts for Generation
- ACL 2021 SimCSE: Simple Contrastive Learning of Sentence Embeddings
- ACL 2021 Implicit Representations of Meaning in Neural Language Models
- ACL 2021 Self-Attention Networks Can Process Bounded Hierarchical Languages
## Eugene
- EMNLP 2021 Improving and Simplifying Pattern Exploiting Training
- EMNLP 2021 ExpBERT: Representation Engineering with Natural Language
- NAACL 2021 Low-Complexity Probing via Finding Subnetworks
- NAACL 2021 Reading and Acting while Blindfolded: The Need for Semantics in Text Game Agents
## Stephy
- ACL 2022 BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Languagemodels
    - Model: BERT(base), BERT(large), RoBERTa(base) - using Huggingface interface
    - Dataset: GLUE 
    - Task: compare GLUE task performances of the below
        - full fine-tuning
        - BitFit: fine-tuning on bias parameter OR fine-tuning on partial bias parameter
- EMNLP 2021 Generating Datasets with Pretrained Language Models
- NAACL 2021 On the Inductive Bias of Masked Language Modeling
- ACL 2021 Modeling Fine-Grained Entity Types with Box Embeddings
